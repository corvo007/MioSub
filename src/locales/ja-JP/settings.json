{
  "title": "設定",
  "tabs": {
    "general": "一般",
    "services": "サービス",
    "performance": "処理設定",
    "enhance": "高度な機能",
    "debug": "開発者向け"
  },
  "general": {
    "display": {
      "title": "表示設定",
      "zoomLevel": "インターフェースの拡大率",
      "zoomHint": "画面の表示サイズを調整します。高解像度画面で窮屈に感じる場合は、値を下げてください（例: 80%）。",
      "language": "インターフェース言語",
      "languageHint": "アプリの表示言語を切り替えます。変更はすぐに反映されます。",
      "zoomOptions": {
        "50": "50% (極小)",
        "67": "67% (小)",
        "75": "75% (やや小)",
        "80": "80% (適度)",
        "90": "90%",
        "100": "100% (デフォルト)",
        "110": "110%",
        "125": "125% (やや大)",
        "150": "150% (極大)"
      }
    },
    "output": {
      "title": "出力設定",
      "targetLanguage": {
        "label": "ターゲット言語",
        "placeholder": "言語を選択",
        "description": "翻訳先の言語"
      },
      "exportMode": "エクスポートモード",
      "bilingual": "バイリンガル字幕",
      "targetOnly": "翻訳のみ",
      "bilingualHint": "バイリンガルモードでは、原文と訳文を並べて表示します。"
    }
  },
  "services": {
    "translation": {
      "title": "翻訳サービス",
      "geminiKey": "Gemini API キー",
      "geminiKeyPlaceholder": "Gemini API キーを入力",
      "geminiKeyHint": "翻訳には <strong>Gemini Flash</strong>、用語抽出・校正には <strong>Gemini Pro</strong> を使用します。",
      "geminiEndpoint": "Gemini エンドポイント（オプション）",
      "geminiEndpointPlaceholder": "https://generativelanguage.googleapis.com",
      "geminiEndpointHint": "カスタムエンドポイントを設定できます。プロキシやAPIゲートウェイに対応しています。"
    },
    "transcription": {
      "title": "音声認識",
      "openaiApi": "OpenAI API",
      "localWhisper": "ローカル Whisper",
      "openaiKey": "OpenAI API キー",
      "openaiKeyPlaceholder": "OpenAI API キーを入力",
      "openaiKeyHint": "OpenAI の <strong>Whisper</strong> モデルで高精度な音声認識を実行します。",
      "openaiEndpoint": "OpenAI エンドポイント（オプション）",
      "openaiEndpointPlaceholder": "https://api.openai.com/v1",
      "openaiEndpointHint": "カスタムエンドポイントを設定できます。ローカルモデル、プロキシ、サードパーティゲートウェイに対応しています。",
      "localWhisperSettings": {
        "modelPathTitle": "モデルファイル",
        "modelPathDesc": "ローカルの Whisper モデル（GGML 形式）を使用します。オフラインで動作します。",
        "modelPathPlaceholder": "モデルファイルを選択...",
        "browseButton": "📁 参照",
        "instructionsTitle": "💡 説明：",
        "instructionGgml": "<strong>GGML形式</strong> の .bin モデルファイルが必要です",
        "instructionModel": "サポート対象は ",
        "instructionModelLink": "whisper.cpp 公式モデル",
        "instructionModelSuffix": " のみです。Faster-whisper モデルはサポートされていません。",
        "selectError": "モデルの選択に失敗しました: {{error}}",
        "selectErrorGeneric": "モデルの選択に失敗しました"
      }
    }
  },
  "performance": {
    "batch": {
      "title": "バッチ処理",
      "proofreadBatchSize": "校正バッチサイズ",
      "proofreadBatchSizeHint": "1回の校正で処理する字幕数です。大きいほど文脈を考慮でき品質が向上しますが、トークン消費も増加します。",
      "translationBatchSize": "翻訳バッチサイズ",
      "translationBatchSizeHint": "1回の翻訳で処理する字幕数です。大きいほど文脈を考慮でき品質が向上しますが、トークン消費も増加します。",
      "chunkDuration": "チャンク長（秒）",
      "chunkDurationHint": "音声分割の目標長さです。文字起こしの並列処理効率に影響します。"
    },
    "concurrency": {
      "title": "同時実行とタイムアウト",
      "concurrencyFlash": "同時実行数 A",
      "concurrencyFlashHint": "対象：メインパイプライン（文字起こし最適化、翻訳）、Whisper API 文字起こし、タイムスタンプ修復。",
      "concurrencyPro": "同時実行数 B",
      "concurrencyProHint": "対象：用語抽出、翻訳校正。",
      "localConcurrency": "同時実行数 C",
      "localConcurrencyHint": "対象：タイムスタンプ調整、ローカル Whisper。",
      "requestTimeout": "リクエストタイムアウト（秒）",
      "requestTimeoutHint": "単一 API リクエストの最大待機時間です。低速ネットワークや大量処理時は増加してください。"
    },
    "audio": {
      "title": "音声処理",
      "smartSplit": "スマート分割",
      "smartSplitDesc": "AI音声検出を使用して自然な停止点で音声を分割し、文字起こし精度を向上（推奨）"
    },
    "cache": {
      "title": "動画プレビューキャッシュ",
      "currentSize": "現在のサイズ",
      "files": "ファイル",
      "clear": "キャッシュをクリア",
      "clearing": "クリア中...",
      "hint": "キャッシュにより、同じ動画を開く際の読み込みが高速化されます。"
    }
  },
  "enhance": {
    "speaker": {
      "title": "話者分離",
      "enableDiarization": "話者分離を有効化",
      "enableDiarizationDesc": "音声中の異なる話者を識別してラベル付けします。",
      "enablePreAnalysis": "話者の事前分析（実験的）",
      "enablePreAnalysisDesc": "字幕生成前に音声を分析し、話者数と声の特徴を識別します。精度が向上しますが、処理時間が増加します。",
      "includeSpeakerInExport": "話者名を出力に含める",
      "includeSpeakerInExportDesc": "字幕ファイルに話者名を表示します（例：話者A：セリフ内容）。",
      "useSpeakerColors": "話者別の色分け（ASS）",
      "useSpeakerColorsDesc": "話者ごとに異なる色を割り当てます（ASS形式のみ）。",
      "styledTranslation": "キャラクター口調翻訳",
      "styledTranslationDesc": "話者の特徴に応じて翻訳の口調を調整します（敬語/タメ口）。",
      "styledTranslationDisabledDesc": "この機能を使用するには「話者の事前分析」を有効にしてください。"
    },
    "glossary": {
      "title": "用語集設定",
      "enableAutoGlossary": "自動用語抽出",
      "enableAutoGlossaryDesc": "専門用語を自動識別・抽出し、翻訳の精度と一貫性を向上させます。",
      "sampleDuration": "用語抽出の対象時間",
      "sampleDurationHint": "音声の先頭 N 分から用語を抽出します。「全体」を選ぶとより網羅的ですが、処理時間が増加します。",
      "sampleOptions": {
        "5": "最初の 5 分",
        "15": "最初の 15 分",
        "30": "最初の 30 分",
        "all": "音声全体（遅め）"
      },
      "autoConfirm": "用語を自動適用",
      "autoConfirmDesc": "抽出した用語を確認なしで直接適用します。新しい用語は現在の用語集に自動マージされます（用語集がない場合は新規作成）。",
      "manageGlossary": "用語集を管理"
    },
    "alignment": {
      "title": "長文分割 ＆ タイムスタンプ調整",
      "mode": "調整モード",
      "modeHint": "校正後の長文分割とタイムスタンプ調整の方法を選択してください。",
      "modeOptions": {
        "none": "なし（元のタイムスタンプを維持）",
        "ctc": "CTC (最高精度)",
        "llm": "LLM (実験的)"
      },
      "ctcConfig": "CTC アライナー設定",
      "ctcConfigDesc": "外部 CTC アライメントツールとモデルのパスを設定してください。",
      "alignerPath": "アライナー実行ファイル",
      "alignerPathPlaceholder": "align.exe を選択...",
      "modelPath": "モデルフォルダ",
      "modelPathPlaceholder": "モデルフォルダを選択...",
      "browseButton": "📁 参照",
      "selectError": "選択に失敗しました: {{error}}",
      "selectErrorGeneric": "選択に失敗しました",
      "instructions": "セットアップ：",
      "instructionAligner": "リリースページから align.exe をダウンロード",
      "instructionModel": "MMS モデル（約1.2GB）をダウンロードして展開",
      "llmHint": "LLM モードは Gemini でタイムスタンプを推定します。CTC より精度は劣りますが、外部依存が不要です。"
    }
  },
  "debug": {
    "title": "開発者モード",
    "description": "Mock モードを有効にすると、実際の API リクエストをスキップしてモックデータを返します。処理フローのテストや API 使用量の節約に便利です。有効にすると、用語抽出と話者の事前分析は自動的にスキップされます。",
    "mockStage": {
      "title": "Mock 開始ステージ",
      "desc": "選択したステージから処理を開始し、それ以前のステージは全てスキップされます。例：「校正」を選択すると文字起こしをスキップし、校正から開始します。Mock モードでは最初のチャンクのみ処理されます。",
      "none": "なし（通常実行）",
      "transcribe": "文字起こし",
      "refinement": "校正",
      "alignment": "タイムスタンプ調整",
      "translation": "翻訳"
    },
    "mockData": {
      "title": "Mock データファイル",
      "placeholder": "JSON/SRT ファイルパス（オプション）",
      "hint": "Mock 開始ステージの入力データとして使用されます。空のままだとプリセットのプレースホルダーデータ（テスト用の単一字幕のみ）が使用されます。後続ステージを効果的にテストするには、実際の字幕ファイルを指定してください。"
    },
    "skipAfter": {
      "title": "処理停止点",
      "desc": "指定ステージで処理を停止",
      "none": "なし（全ステージ実行）",
      "transcribe": "文字起こし",
      "refinement": "校正",
      "alignment": "タイムスタンプ調整"
    },
    "language": {
      "title": "Mock 用言語",
      "desc": "タイムスタンプ調整用の言語（自動検出を上書き）"
    },
    "saveIntermediateArtifacts": "中間ファイルを保存",
    "saveIntermediateArtifactsDesc": "Whisper の生データ、校正結果、翻訳結果などをログフォルダに保存（デバッグ用）",
    "customPaths": "カスタムパス",
    "ffmpegPath": "カスタム ffmpeg.exe パス",
    "ffprobePath": "カスタム ffprobe.exe パス",
    "whisperPath": "カスタム whisper-cli.exe パス",
    "defaultAutoDetected": "デフォルト（自動検出）"
  },
  "languages": {
    "simplifiedChinese": "簡体字中国語",
    "traditionalChinese": "繁体字中国語",
    "english": "英語",
    "japanese": "日本語",
    "korean": "韓国語",
    "spanish": "スペイン語",
    "french": "フランス語",
    "german": "ドイツ語",
    "russian": "ロシア語",
    "portuguese": "ポルトガル語",
    "italian": "イタリア語",
    "vietnamese": "ベトナム語",
    "thai": "タイ語",
    "indonesian": "インドネシア語"
  }
}
